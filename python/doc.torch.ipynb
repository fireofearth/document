{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]),\n",
       " torch.Size([2, 2]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of size (2, 2)\n",
    "# Usually, use torch.tensor() instead of torch.Tensor() as the former is the (default) factory method.\n",
    "A = torch.tensor([[1,2],[3,4]])\n",
    "B = torch.arange(4).reshape((2,2))\n",
    "# Loop through the first axis of a tensor\n",
    "for a in A:\n",
    "    print(a)\n",
    "A.shape, B.shape, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverting a tensor of booleans\n",
    "a = torch.tensor([True,False,True])\n",
    "~a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 1.], dtype=torch.float64), 'torch.DoubleTensor')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting one type to the torch.DoubleTensor (aka. float64)\n",
    "a = torch.tensor([True,False,True])\n",
    "a.double(), a.double().type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking along a new axis 0\n",
    "a = torch.Tensor([1,2])\n",
    "b = torch.Tensor([3,4])\n",
    "c = torch.Tensor([5,6])\n",
    "torch.stack([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 5.],\n",
       "        [2., 4., 6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking along new axis 1\n",
    "torch.stack([a,b,c], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating tensors together\n",
    "# no new dimension is introduced\n",
    "torch.cat([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6],\n",
       "         [7, 8]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [7, 8]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convenience function to remove a row from a tensor\n",
    "A = (torch.arange(8) + 1).reshape((4, 2))\n",
    "a = 2\n",
    "A, torch.cat([A[:a], A[a + 1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " torch.Size([2, 3]),\n",
       " torch.Size([1, 2, 3]),\n",
       " torch.Size([2, 1, 3]),\n",
       " torch.Size([2, 3, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.shape, A.unsqueeze(0).shape, A.unsqueeze(1).shape, A.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[[0],\n",
       "          [1],\n",
       "          [2]],\n",
       " \n",
       "         [[3],\n",
       "          [4],\n",
       "          [5]]]),\n",
       " torch.Size([2, 3, 1]),\n",
       " torch.Size([2, 1, 3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.shape, A.unsqueeze(-1), A.unsqueeze(-1).shape, A.unsqueeze(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2, 0, 1, 2],\n",
       "         [3, 4, 5, 3, 4, 5]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.repeat((2,1)), A.repeat((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2, 0, 1, 2],\n",
       "         [3, 4, 5, 3, 4, 5]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tile() is the same as Tensor.repeat()\n",
    "A = torch.arange(6).reshape((2,3))\n",
    "A, torch.tile(A, (2,1)), torch.tile(A, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 2]),\n",
       " torch.Size([3, 2, 2, 2]),\n",
       " tensor([[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       " \n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]],\n",
       " \n",
       "         [[ 8,  9],\n",
       "          [10, 11]]]),\n",
       " tensor([[[[ 0,  1],\n",
       "           [ 0,  1]],\n",
       " \n",
       "          [[ 2,  3],\n",
       "           [ 2,  3]]],\n",
       " \n",
       " \n",
       "         [[[ 4,  5],\n",
       "           [ 4,  5]],\n",
       " \n",
       "          [[ 6,  7],\n",
       "           [ 6,  7]]],\n",
       " \n",
       " \n",
       "         [[[ 8,  9],\n",
       "           [ 8,  9]],\n",
       " \n",
       "          [[10, 11],\n",
       "           [10, 11]]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicating a matrix along a new axis using torch.tile()\n",
    "A = torch.arange(12).reshape((3,2,2))\n",
    "B = torch.tile(A.unsqueeze(2), (2, 1))\n",
    "A.shape, B.shape, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(36), tensor([16, 20]), tensor([ 3,  7, 11, 15]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sums\n",
    "A = (torch.arange(8) + 1).reshape((4, 2))\n",
    "torch.sum(A), torch.sum(A, dim=0), torch.sum(A, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7183, 5.4366],\n",
       "        [0.0000, 2.7183]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1, 2], [0, 1]])\n",
    "torch.matrix_exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]],\n",
       "\n",
       "        [[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]],\n",
       "\n",
       "        [[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[[1, 2], [0, 1]], [[1, 2], [0, 1]], [[1, 2], [0, 1]]])\n",
    "torch.matrix_exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2., -2.],\n",
       "         [ 8., -2.]]),\n",
       " tensor([[7., 3.],\n",
       "         [3., 2.]]),\n",
       " tensor([[[ 2., -2.],\n",
       "          [ 8., -2.]],\n",
       " \n",
       "         [[ 7.,  3.],\n",
       "          [ 3.,  2.]]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batched Matrix-matrix multiplication using np.einsum()\n",
    "# Matrix-matrix multiplication\n",
    "A = torch.Tensor([\n",
    "    [\n",
    "        [1, 2],\n",
    "        [4, 2]\n",
    "    ],[\n",
    "        [3, 1],\n",
    "        [2,-1]\n",
    "    ]\n",
    "])\n",
    "B = torch.Tensor([\n",
    "    [\n",
    "        [2, 0],\n",
    "        [0, -1]\n",
    "    ],[\n",
    "        [2, 1],\n",
    "        [1, 0]\n",
    "    ]\n",
    "])\n",
    "A[0] @ B[0], A[1] @ B[1], torch.einsum(\"...ij,...jk->...ik\", A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.),\n",
       " tensor(1.),\n",
       " tensor(3.),\n",
       " tensor(2.),\n",
       " tensor([[5., 1.],\n",
       "         [3., 2.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trace\n",
    "A1 = torch.Tensor([[ 1, 2], [3, 4]])\n",
    "A2 = torch.Tensor([[-1, 2], [3, 2]])\n",
    "A3 = torch.Tensor([[ 2,-1], [3, 1]])\n",
    "A4 = torch.Tensor([[ 2, 1], [1, 0]])\n",
    "A = torch.stack([\n",
    "    torch.stack([A1, A2]),\n",
    "    torch.stack([A3, A4])])\n",
    "torch.trace(A1), torch.trace(A2), torch.trace(A3), \\\n",
    "        torch.trace(A4), torch.einsum(\"...ii\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3450,  0.3728],\n",
       "        [ 0.4188, -0.8023]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(2,2,2)\n",
    "values, indices = A.max(0)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8009,  0.5166],\n",
       "         [ 0.4627, -0.4415]],\n",
       "\n",
       "        [[ 0.0510,  2.5605],\n",
       "         [-0.6070,  0.3585]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(2,2,2).unsqueeze(0)\n",
    "values, indices = A.max(0)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-78f446b2981e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2], device='cuda')\n",
    "a / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, selection and manipulating tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7],\n",
       "         [3]]),\n",
       " tensor([[1],\n",
       "         [4],\n",
       "         [5],\n",
       "         [8]]),\n",
       " tensor([1, 4, 5, 8]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicing tensors.\n",
    "# Cannot use ndarray or lists as indices. They must be integer/long tensors.\n",
    "A = torch.tensor([\n",
    "        [1,2],\n",
    "        [3,4],\n",
    "        [5,6],\n",
    "        [7,8]])\n",
    "ind1 = torch.tensor([[0],[1],[0],[1]])\n",
    "ind2 = torch.tensor([[3],[1]])\n",
    "torch.gather(A, 0, ind2), torch.gather(A, 1, ind1), torch.gather(A, 1, ind1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4],\n",
       "         [7, 6]]),\n",
       " tensor([[1, 2],\n",
       "         [4, 3],\n",
       "         [5, 6]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Advanced usage of torch.gather()\n",
    "# Documentation for torch.gather()\n",
    "# https://stackoverflow.com/questions/50999977/what-does-the-gather-function-do-in-pytorch-in-layman-terms\n",
    "A = torch.tensor([\n",
    "        [1,2],\n",
    "        [3,4],\n",
    "        [5,6],\n",
    "        [7,8]])\n",
    "ind1 = torch.tensor([[0,1],[3,2]])\n",
    "ind2 = torch.tensor([[0,1],[1,0],[0,1]])\n",
    "torch.gather(A, 0, ind1), torch.gather(A, 1, ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 1],\n",
       "         [4, 5]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using masks to select subtensors\n",
    "A = torch.arange(6).reshape(-1, 2)\n",
    "mask = torch.tensor([True,False,True])\n",
    "A, A[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 2.],\n",
       "          [3., 4.]],\n",
       " \n",
       "         [[5., 6.],\n",
       "          [7., 8.]]]),\n",
       " tensor([[1., 2., 3., 4.],\n",
       "         [5., 6., 7., 8.]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping tensors\n",
    "A = torch.Tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "A, A.reshape((2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
