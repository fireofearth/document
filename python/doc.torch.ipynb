{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as torchdata\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import utility as util\n",
    "import utility.doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [2, 3]]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor directly from ndarray using torch.tensor()\n",
    "A = np.arange(4).reshape(2,2)\n",
    "A, torch.tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]),\n",
       " torch.Size([2, 2]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of size (2, 2)\n",
    "# Usually, use torch.tensor() instead of torch.Tensor() as the former is the (default) factory method.\n",
    "A = torch.tensor([[1,2],[3,4]])\n",
    "B = torch.arange(4).reshape((2,2))\n",
    "# Loop through the first axis of a tensor\n",
    "for a in A:\n",
    "    print(a)\n",
    "A.shape, B.shape, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverting a tensor of booleans\n",
    "a = torch.tensor([True,False,True])\n",
    "~a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 1.], dtype=torch.float64), 'torch.DoubleTensor')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting one type to the torch.DoubleTensor (aka. float64)\n",
    "a = torch.tensor([True,False,True])\n",
    "a.double(), a.double().type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ True,  True,  True, False]), tensor([False, False,  True, False]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean array operations\n",
    "a = torch.tensor([True,False,True,False])\n",
    "b = torch.tensor([False,True,True,False])\n",
    "a | b, a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.],\n",
       "         [3., 4.],\n",
       "         [5., 6.]]),\n",
       " tensor([[1., 3., 5.],\n",
       "         [2., 4., 6.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking along a new axis 0 and axis 1\n",
    "a = torch.Tensor([1,2]); b = torch.Tensor([3,4]); c = torch.Tensor([5,6])\n",
    "torch.stack([a,b,c]), torch.stack([a,b,c], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating tensors together\n",
    "# no new dimension is introduced\n",
    "a = torch.Tensor([1,2]); b = torch.Tensor([3,4]); c = torch.Tensor([5,6])\n",
    "torch.cat([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6],\n",
       "         [7, 8]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [7, 8]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convenience function to remove a row from a tensor\n",
    "A = (torch.arange(8) + 1).reshape((4, 2))\n",
    "a = 2\n",
    "A, torch.cat([A[:a], A[a + 1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " torch.Size([2, 3]),\n",
       " torch.Size([1, 2, 3]),\n",
       " torch.Size([2, 1, 3]),\n",
       " torch.Size([2, 3, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.shape, A.unsqueeze(0).shape, A.unsqueeze(1).shape, A.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[[0],\n",
       "          [1],\n",
       "          [2]],\n",
       " \n",
       "         [[3],\n",
       "          [4],\n",
       "          [5]]]),\n",
       " torch.Size([2, 3, 1]),\n",
       " torch.Size([2, 1, 3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.shape, A.unsqueeze(-1), A.unsqueeze(-1).shape, A.unsqueeze(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2, 0, 1, 2],\n",
       "         [3, 4, 5, 3, 4, 5]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape((2,3))\n",
    "A, A.repeat((2,1)), A.repeat((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([[0, 1, 2, 0, 1, 2],\n",
       "         [3, 4, 5, 3, 4, 5]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tile() is the same as Tensor.repeat()\n",
    "A = torch.arange(6).reshape((2,3))\n",
    "A, torch.tile(A, (2,1)), torch.tile(A, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 2]),\n",
       " torch.Size([3, 2, 2, 2]),\n",
       " tensor([[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       " \n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]],\n",
       " \n",
       "         [[ 8,  9],\n",
       "          [10, 11]]]),\n",
       " tensor([[[[ 0,  1],\n",
       "           [ 0,  1]],\n",
       " \n",
       "          [[ 2,  3],\n",
       "           [ 2,  3]]],\n",
       " \n",
       " \n",
       "         [[[ 4,  5],\n",
       "           [ 4,  5]],\n",
       " \n",
       "          [[ 6,  7],\n",
       "           [ 6,  7]]],\n",
       " \n",
       " \n",
       "         [[[ 8,  9],\n",
       "           [ 8,  9]],\n",
       " \n",
       "          [[10, 11],\n",
       "           [10, 11]]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicating a matrix along a new axis using torch.tile()\n",
    "A = torch.arange(12).reshape((3,2,2))\n",
    "B = torch.tile(A.unsqueeze(2), (2, 1))\n",
    "A.shape, B.shape, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(36), tensor([16, 20]), tensor([ 3,  7, 11, 15]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sums\n",
    "A = (torch.arange(8) + 1).reshape((4, 2))\n",
    "torch.sum(A), torch.sum(A, dim=0), torch.sum(A, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7183, 5.4366],\n",
       "        [0.0000, 2.7183]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1, 2], [0, 1]])\n",
    "torch.matrix_exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]],\n",
       "\n",
       "        [[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]],\n",
       "\n",
       "        [[2.7183, 5.4366],\n",
       "         [0.0000, 2.7183]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[[1, 2], [0, 1]], [[1, 2], [0, 1]], [[1, 2], [0, 1]]])\n",
    "torch.matrix_exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2., -2.],\n",
       "         [ 8., -2.]]),\n",
       " tensor([[7., 3.],\n",
       "         [3., 2.]]),\n",
       " tensor([[[ 2., -2.],\n",
       "          [ 8., -2.]],\n",
       " \n",
       "         [[ 7.,  3.],\n",
       "          [ 3.,  2.]]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batched Matrix-matrix multiplication using np.einsum()\n",
    "# Matrix-matrix multiplication\n",
    "A = torch.Tensor([\n",
    "    [\n",
    "        [1, 2],\n",
    "        [4, 2]\n",
    "    ],[\n",
    "        [3, 1],\n",
    "        [2,-1]\n",
    "    ]\n",
    "])\n",
    "B = torch.Tensor([\n",
    "    [\n",
    "        [2, 0],\n",
    "        [0, -1]\n",
    "    ],[\n",
    "        [2, 1],\n",
    "        [1, 0]\n",
    "    ]\n",
    "])\n",
    "A[0] @ B[0], A[1] @ B[1], torch.einsum(\"...ij,...jk->...ik\", A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.),\n",
       " tensor(1.),\n",
       " tensor(3.),\n",
       " tensor(2.),\n",
       " tensor([[5., 1.],\n",
       "         [3., 2.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trace\n",
    "A1 = torch.Tensor([[ 1, 2], [3, 4]])\n",
    "A2 = torch.Tensor([[-1, 2], [3, 2]])\n",
    "A3 = torch.Tensor([[ 2,-1], [3, 1]])\n",
    "A4 = torch.Tensor([[ 2, 1], [1, 0]])\n",
    "A = torch.stack([\n",
    "    torch.stack([A1, A2]),\n",
    "    torch.stack([A3, A4])])\n",
    "torch.trace(A1), torch.trace(A2), torch.trace(A3), \\\n",
    "        torch.trace(A4), torch.einsum(\"...ii\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3450,  0.3728],\n",
       "        [ 0.4188, -0.8023]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(2,2,2)\n",
    "values, indices = A.max(0)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8009,  0.5166],\n",
       "         [ 0.4627, -0.4415]],\n",
       "\n",
       "        [[ 0.0510,  2.5605],\n",
       "         [-0.6070,  0.3585]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(2,2,2).unsqueeze(0)\n",
    "values, indices = A.max(0)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, selection and manipulating tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [5, 6],\n",
       "        [3, 4],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([\n",
    "        [1,2],\n",
    "        [3,4],\n",
    "        [5,6],\n",
    "        [7,8]])\n",
    "indices = torch.tensor([0, 2, 1, 0], dtype=torch.long)\n",
    "A[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7],\n",
       "         [3]]),\n",
       " tensor([[1],\n",
       "         [4],\n",
       "         [5],\n",
       "         [8]]),\n",
       " tensor([1, 4, 5, 8]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicing tensors.\n",
    "# Cannot use ndarray or lists as indices. They must be integer/long tensors.\n",
    "A = torch.tensor([\n",
    "        [1,2],\n",
    "        [3,4],\n",
    "        [5,6],\n",
    "        [7,8]])\n",
    "ind1 = torch.tensor([[0],[1],[0],[1]])\n",
    "ind2 = torch.tensor([[3],[1]])\n",
    "torch.gather(A, 0, ind2), torch.gather(A, 1, ind1), torch.gather(A, 1, ind1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q_values has shape (batch=2, history=3, 2)\n",
    "Q_values = torch.tensor([\n",
    "    # batch\n",
    "    [\n",
    "        # history\n",
    "        [1, 2],\n",
    "        [3, 4],\n",
    "        [5, 6],\n",
    "    ],[\n",
    "        [ 7,  8],\n",
    "        [ 9, 10],\n",
    "        [11, 12]\n",
    "    ]\n",
    "])\n",
    "# actions has shape (batch=2,history=3,1)\n",
    "actions = torch.tensor([\n",
    "    # batch\n",
    "    [\n",
    "        # history\n",
    "        [0],\n",
    "        [1],\n",
    "        [0]\n",
    "    ],[\n",
    "        [0],\n",
    "        [0],\n",
    "        [1]\n",
    "    ]\n",
    "])\n",
    "_Q_values = Q_values.gather(2, actions).squeeze(2)\n",
    "_Q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4],\n",
       "         [7, 6]]),\n",
       " tensor([[1, 2],\n",
       "         [4, 3],\n",
       "         [5, 6]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Advanced usage of torch.gather()\n",
    "# Documentation for torch.gather()\n",
    "# https://stackoverflow.com/questions/50999977/what-does-the-gather-function-do-in-pytorch-in-layman-terms\n",
    "A = torch.tensor([\n",
    "        [1,2],\n",
    "        [3,4],\n",
    "        [5,6],\n",
    "        [7,8]])\n",
    "ind1 = torch.tensor([[0,1],[3,2]])\n",
    "ind2 = torch.tensor([[0,1],[1,0],[0,1]])\n",
    "torch.gather(A, 0, ind1), torch.gather(A, 1, ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 1],\n",
       "         [4, 5]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using masks to select subtensors\n",
    "A = torch.arange(6).reshape(-1, 2)\n",
    "mask = torch.tensor([True,False,True])\n",
    "A, A[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 2.],\n",
       "          [3., 4.]],\n",
       " \n",
       "         [[5., 6.],\n",
       "          [7., 8.]]]),\n",
       " tensor([[1., 2., 3., 4.],\n",
       "         [5., 6., 7., 8.]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping tensors\n",
    "A = torch.Tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "A, A.reshape((2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False,  True,  True],\n",
       "         [False,  True, False],\n",
       "         [ True, False, False]]),\n",
       " tensor([1, 2, 4, 6]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting entries from a tensor as a vector\n",
    "\"\"\"\n",
    "tensor([[0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "        [6, 7, 8]])\n",
    "\"\"\"\n",
    "A = torch.arange(9).reshape(3,3)\n",
    "B = torch.zeros(A.shape, dtype=torch.bool)\n",
    "B[0,1] = True\n",
    "B[0,2] = True\n",
    "B[1,1] = True\n",
    "B[2,0] = True\n",
    "B, A[B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9266, 0.6806, 0.9140, 0.8071, 0.2495],\n",
       "         [0.8059, 0.1397, 0.9016, 0.3367, 0.5274],\n",
       "         [0.5550, 0.8124, 0.9493, 0.2014, 0.6831]]),\n",
       " tensor([[0.2495, 0.6806, 0.8071, 0.9140, 0.9266],\n",
       "         [0.1397, 0.3367, 0.5274, 0.8059, 0.9016],\n",
       "         [0.2014, 0.5550, 0.6831, 0.8124, 0.9493]]),\n",
       " tensor([[4, 1, 3, 2, 0],\n",
       "         [1, 3, 4, 0, 2],\n",
       "         [3, 0, 4, 1, 2]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting each sample in a batch of values\n",
    "A = torch.rand(3, 5)\n",
    "values, indices = torch.sort(A, dim=1)\n",
    "A, values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1,  -1],\n",
       "         [  2, 100],\n",
       "         [  3,   0],\n",
       "         [  4,   1]],\n",
       "\n",
       "        [[  1,   1],\n",
       "         [  2, 100],\n",
       "         [  3,  -1],\n",
       "         [  4,   0]],\n",
       "\n",
       "        [[  1, 100],\n",
       "         [  2,   1],\n",
       "         [  3,   0],\n",
       "         [  4,  -1]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort batched tensors of shape (batch size, length, n dimensions) along the first column \n",
    "A = torch.tensor([\n",
    "    [\n",
    "        [2, 100],\n",
    "        [1, -1],\n",
    "        [4, 1],\n",
    "        [3, 0]\n",
    "    ],[\n",
    "        [1, 1],\n",
    "        [4, 0],\n",
    "        [2, 100],\n",
    "        [3, -1]\n",
    "    ],[\n",
    "        [3, 0],\n",
    "        [2, 1],\n",
    "        [1, 100],\n",
    "        [4, -1]\n",
    "    ]\n",
    "]) # has shape (3, 4, 2)\n",
    "# sort A by first column by selecting that column\n",
    "# and get indices to apply to A\n",
    "# indices has shape (3, 4)\n",
    "_, indices = torch.sort(A[...,0], dim=1)\n",
    "# repeat indices since we want to apply indices to both columns\n",
    "# indices has shape (3, 4, 2)\n",
    "indices = indices.unsqueeze(-1).repeat(1,1,2)\n",
    "# use gather to sort A itself\n",
    "torch.gather(A, 1, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  0,  0,  0],\n",
       "         [ 2,  3,  0,  0,  0],\n",
       "         [ 4,  5,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 6,  7,  0,  0,  0],\n",
       "         [ 8,  9,  0,  0,  0],\n",
       "         [10, 11,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Padding tensor at the end of an array\n",
    "tensor([[[ 0,  1],\n",
    "         [ 2,  3],\n",
    "         [ 4,  5]],\n",
    "\n",
    "        [[ 6,  7],\n",
    "         [ 8,  9],\n",
    "         [10, 11]]])\n",
    "\"\"\"\n",
    "A = torch.arange(12).reshape(2,3,2)\n",
    "# second argument specifies padding at\n",
    "# (front of n-th axis, back of n-th axis, front of axis n-1, back of axis n-1, ...)\n",
    "F.pad(A, (0,3,0,2,0,1), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  1,  0,  0,  0],\n",
       "         [ 2,  3,  0,  0,  0],\n",
       "         [ 4,  5,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0,  0,  0],\n",
       "         [ 6,  7,  0,  0,  0],\n",
       "         [ 8,  9,  0,  0,  0],\n",
       "         [10, 11,  0,  0,  0]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Padding tensor at some parts of an array\"\"\"\n",
    "A = torch.arange(12).reshape(2,3,2)\n",
    "# second argument specifies padding at\n",
    "# (front of n-th axis, back of n-th axis, front of axis n-1, back of axis n-1, ...)\n",
    "F.pad(A, (0,3,1,0), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  1],\n",
       "         [ 0,  0,  0,  2,  3],\n",
       "         [ 0,  0,  0,  4,  5]],\n",
       "\n",
       "        [[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  6,  7],\n",
       "         [ 0,  0,  0,  8,  9],\n",
       "         [ 0,  0,  0, 10, 11]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Padding tensor at the front of an array\"\"\"\n",
    "A = torch.arange(12).reshape(2,3,2)\n",
    "# second argument specifies padding at\n",
    "# (front of n-th axis, back of n-th axis, front of axis n-1, back of axis n-1, ...)\n",
    "F.pad(A, (3,0,2,0,1,0), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0,  1],\n",
       "         [ 0,  0,  0,  2,  3],\n",
       "         [ 0,  0,  0,  4,  5]],\n",
       "\n",
       "        [[ 0,  0,  0,  6,  7],\n",
       "         [ 0,  0,  0,  8,  9],\n",
       "         [ 0,  0,  0, 10, 11]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12).reshape(2,3,2)\n",
    "F.pad(A, (3,0), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-6, -5, -4, -3],\n",
       "         [-2, -1,  0,  1],\n",
       "         [ 2,  3,  4,  5]]),\n",
       " tensor([[-1, -1, -1, -1],\n",
       "         [-1, -1,  0,  1],\n",
       "         [ 1,  1,  1,  1]]),\n",
       " (tensor([0, 0, 0, 0, 1, 1, 1, 1]), tensor([0, 1, 2, 3, 0, 1, 2, 3])))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the array using np.where()\n",
    "A = torch.arange(12).reshape(3, 4) - 6\n",
    "A, torch.where(A < 0, -1, 0) + torch.where(A > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-6, -5, -4, -3],\n",
       "         [-2, -1,  0,  1],\n",
       "         [ 2,  3,  4,  5]], dtype=torch.int32),\n",
       " tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]], dtype=torch.int32),\n",
       " tensor([[0, 1, 2, 3],\n",
       "         [4, 5, 0, 0],\n",
       "         [0, 0, 0, 0]], dtype=torch.int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning arrays using masks\n",
    "A = torch.arange(12, dtype=torch.int).reshape(3, 4) - 6\n",
    "B = torch.arange(12, dtype=torch.int).reshape(3, 4)\n",
    "C = torch.zeros(A.shape, dtype=torch.int)\n",
    "C[A < 0] = B[A < 0]\n",
    "A, B, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "There is no `torch` equivalent of `np.random.choice()`. See:\n",
    "<https://discuss.pytorch.org/t/torch-equivalent-of-numpy-random-choice/16146/4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 6, 3, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample indices without replacement\n",
    "N = 10 # we will sample indices from [0, 1, 2, ..., N - 1]\n",
    "k = 5 # we will sample k elements\n",
    "generator = torch.Generator()\n",
    "torch.multinomial(torch.ones(N, dtype=torch.float), k, replacement=False, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve samples and labels of the training set in the training loop.\n",
      "tensor([8., 9., 4.]) tensor([0, 0, 0])\n",
      "tensor([ 3., 19., 22.]) tensor([0, 1, 1])\n",
      "tensor([23., 17., 13.]) tensor([1, 1, 1])\n",
      "tensor([11.,  6., 20.]) tensor([0, 0, 1])\n",
      "tensor([ 5., 18.,  0.]) tensor([0, 1, 0])\n",
      "tensor([16.,  1., 14.]) tensor([1, 0, 1])\n",
      "Retrieve samples and labels in the testing set in the evaluation loop.\n",
      "tensor([ 7., 12.,  2.]) tensor([0, 1, 0])\n",
      "tensor([21., 10., 15.]) tensor([1, 0, 1])\n",
      "Sampling indices from SubsetRandomSampler\n",
      "0 2 5 3 4 1 \n"
     ]
    }
   ],
   "source": [
    "# using datasets, index sampling and data loader\n",
    "class MyDataset(torchdata.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.__data = data\n",
    "        self.__labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.__data[idx], dtype=torch.float),\n",
    "            torch.tensor(self.__labels[idx], dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.__labels)\n",
    "\n",
    "data   = np.arange(24)\n",
    "labels = [0]*12 + [1]*12\n",
    "dataset = MyDataset(data, labels)\n",
    "generator = torch.Generator()\n",
    "split = [18, 6]\n",
    "trainset, testset = torchdata.random_split(dataset, split, generator=generator)\n",
    "\n",
    "trainsampler = torchdata.SubsetRandomSampler(range(split[0]), generator=generator)\n",
    "trainloader = torchdata.DataLoader(trainset, sampler=trainsampler, batch_size=3, num_workers=1)\n",
    "\n",
    "testsampler = torchdata.SubsetRandomSampler(range(split[1]), generator=generator)\n",
    "testloader = torchdata.DataLoader(testset, sampler=testsampler, batch_size=3, num_workers=1)\n",
    "\n",
    "print(\"Retrieve samples and labels of the training set in the training loop.\")\n",
    "for samples, labels in trainloader:\n",
    "    print(samples, labels)\n",
    "print(\"Retrieve samples and labels in the testing set in the evaluation loop.\")\n",
    "for samples, labels in testloader:\n",
    "    print(samples, labels)\n",
    "print(\"Sampling indices from SubsetRandomSampler\")\n",
    "for i in testsampler:\n",
    "    print(i, end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 loss function\n",
    "criterion = nn.SmoothL1Loss()\n",
    "a = torch.tensor([0,1,1,2], dtype=torch.float).reshape(2,2)\n",
    "b = torch.tensor([0,1,2,0], dtype=torch.float).reshape(2,2)\n",
    "loss = criterion(a, b)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of mlp given [0.8, 0.2]\n",
      "[0.   0.   0.   0.85 0.   0.   0.08 0.75]\n",
      "\n",
      "shape of output\n",
      "(8,)\n",
      "\n",
      "output of mlp given [[0.8, 0.2],[0.4, 0.6]]\n",
      "[[0.   0.   0.   0.85 0.   0.   0.08 0.75]\n",
      " [0.09 0.02 0.   0.54 0.04 0.   0.04 0.8 ]]\n",
      "\n",
      "shape of output\n",
      "(2, 8)\n",
      "\n",
      "output of mlp given input of shape (2,3,2)\n",
      "[[[0.   0.   0.   0.85 0.   0.   0.08 0.75]\n",
      "  [0.09 0.02 0.   0.54 0.04 0.   0.04 0.8 ]\n",
      "  [0.41 0.06 0.05 0.3  0.33 0.   0.01 0.84]]\n",
      "\n",
      " [[0.05 0.45 0.   0.57 0.   0.   0.11 0.73]\n",
      "  [0.3  0.   0.03 0.38 0.26 0.   0.   0.84]\n",
      "  [0.09 0.15 0.   0.54 0.01 0.   0.06 0.78]]]\n",
      "\n",
      "shape of output\n",
      "(2, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "# Linear takes in input with multiple dimensions, and linear only applies the last dimension.\n",
    "mlp = nn.Sequential()\n",
    "mlp.add_module(\"linear\", nn.Linear(2, 8))\n",
    "mlp.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "\n",
    "def do_mlp(x):\n",
    "    x = torch.tensor(x)\n",
    "    h = mlp(x)\n",
    "    return h.detach().numpy()\n",
    "\n",
    "h1 = do_mlp([0.8, 0.2])\n",
    "h2 = do_mlp([[0.8, 0.2],[0.4, 0.6]])\n",
    "h3 = do_mlp([\n",
    "    [\n",
    "        [0.8, 0.2],\n",
    "        [0.4, 0.6],\n",
    "        [0.1, 0.9]\n",
    "    ],[\n",
    "        [0.1, 0.2],\n",
    "        [0.3, 0.9],\n",
    "        [0.3, 0.5]\n",
    "    ]\n",
    "])\n",
    "util.doc.results(\n",
    "    \"output of mlp given [0.8, 0.2]\", np.round(h1, 2),\n",
    "    \"shape of output\", h1.shape,\n",
    "    \"output of mlp given [[0.8, 0.2],[0.4, 0.6]]\", np.round(h2, 2),\n",
    "    \"shape of output\", h2.shape,\n",
    "    \"output of mlp given input of shape (2,3,2)\", np.round(h3, 2),\n",
    "    \"shape of output\", h3.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0147, -1.0108]) tensor([0.1709, 0.0407])\n",
      "batch norm running mean\n",
      "tensor([ 1.0147, -1.0108])\n",
      "\n",
      "batch norm running variance\n",
      "tensor([0.1709, 0.0407])\n",
      "\n",
      "output of bn given [1, -1]\n",
      "[[-0.04  0.05]]\n",
      "\n",
      "shape of output\n",
      "(1, 2)\n",
      "\n",
      "output of bn given data 1 std away\n",
      "[[ 0.93  1.04]\n",
      " [-1.   -0.94]]\n",
      "\n",
      "shape of output\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "dist1 = torch.distributions.normal.Normal(loc= 1.0, scale=0.4)\n",
    "dist2 = torch.distributions.normal.Normal(loc=-1.0, scale=0.2)\n",
    "\n",
    "def get_x():\n",
    "    x1 = dist1.sample((10,))\n",
    "    x2 = dist2.sample((10,))\n",
    "    return torch.hstack((x1[:,None], x2[:,None]))\n",
    "\n",
    "# updates running mean and std using exponentially moving average.\n",
    "# Setting momentum to 0 makes batch norm fail.\n",
    "bn = nn.BatchNorm1d(2, momentum=0.1)\n",
    "\n",
    "bn.train()\n",
    "for _ in range(100):\n",
    "    x = get_x()\n",
    "    h = bn(x)\n",
    "bn.eval()\n",
    "\n",
    "def do_bn(x):\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    h = bn(x)\n",
    "    return h.detach().numpy()\n",
    "\n",
    "print(bn.running_mean, bn.running_var)\n",
    "\n",
    "h1 = do_bn([[1,-1]])\n",
    "h2 = do_bn([\n",
    "    [1.4, -0.8],\n",
    "    [0.6, -1.2]\n",
    "])\n",
    "\n",
    "util.doc.results(\n",
    "    \"batch norm running mean\", bn.running_mean,\n",
    "    \"batch norm running variance\", bn.running_var,\n",
    "    \"output of bn given [1, -1]\", np.round(h1, 2),\n",
    "    \"shape of output\", h1.shape,\n",
    "    \"output of bn given data 1 std away\", np.round(h2, 2),\n",
    "    \"shape of output\", h2.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.348113, grad_fn=<MulBackward0>)\n",
      "Torch gradients\n",
      "tensor([[0.004284, 0.007141],\n",
      "        [0.004459, 0.007431]], grad_fn=<CopyBackwards>)\n",
      "tensor([[ 0.078441,  0.080391],\n",
      "        [-0.012035, -0.012334]], grad_fn=<CopyBackwards>)\n",
      "Weights after update\n",
      "tensor([[0.497858, 0.546430],\n",
      "        [0.597771, 0.646284]], requires_grad=True)\n",
      "tensor([[0.660779, 0.709805],\n",
      "        [0.806018, 0.856167]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Manual Neural Network, MSE loss, using PyTorch\n",
    "W1 = torch.tensor([[0.5, 0.55], [0.6, 0.65]], requires_grad=True)\n",
    "W2 = torch.tensor([[0.7, 0.75], [0.8, 0.85]], requires_grad=True)\n",
    "b1 = torch.tensor([0.35, 0.35])\n",
    "b2 = torch.tensor([0.6, 0.6])\n",
    "x = torch.tensor([0.3, 0.5])\n",
    "y = torch.tensor([0.01, 0.99])\n",
    "\n",
    "optimizer = torch.optim.SGD([W1, W2], lr=0.5)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "yhat = torch.sigmoid(W2 @ torch.sigmoid(W1 @ x + b1) + b2)\n",
    "E_total = 0.5*torch.sum((y - yhat)**2)\n",
    "torch.set_printoptions(precision=6)\n",
    "print(E_total)\n",
    "E_total.backward(create_graph=True)\n",
    "print(\"Torch gradients\")\n",
    "print(W1.grad)\n",
    "print(W2.grad)\n",
    "\n",
    "optimizer.step()\n",
    "print(\"Weights after update\")\n",
    "print(W1)\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
