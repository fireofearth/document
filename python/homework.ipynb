{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import pprint\n",
    "import scipy\n",
    "import scipy.special\n",
    "import scipy.spatial\n",
    "import scipy.stats\n",
    "import scipy.stats.qmc\n",
    "import scipy.ndimage\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "import matplotlib\n",
    "import matplotlib.patches\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mc\n",
    "from matplotlib.path import Path\n",
    "from tabulate import tabulate\n",
    "import networkx as nx\n",
    "import math as m\n",
    "import torch\n",
    "\n",
    "import utility as util\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic MDP homework\n",
    "P = np.array([\n",
    "    [0.2, 0.64, 0.16, 0],\n",
    "    [0.5, 0,    0.5,  0],\n",
    "    [0,   0,    0.5,  0.5],\n",
    "    [0,   1,    0,    0]\n",
    "])\n",
    "# Expected immediate reward for next transition\n",
    "R = np.array([1.96, 0.5, 2, 1])\n",
    "# Value function V(s) = E_{a~\\pi(s)}[r(s,a) + \\gamma \\sum_{s'} P(s' | s, a) V(s')]\n",
    "# Expression for value function V = R + \\gamma P V => (I - \\gamma P) V = R\n",
    "# A = I - \\gamma P; \\gamma = 0.8\n",
    "A = np.identity(4) - 0.8*P\n",
    "np.linalg.solve(A, R)\n",
    "# gives np.array([7.37870117, 6.42137348, 7.42473252, 6.13709878])\n",
    "V = np.array([7.37870117, 6.42137348, 7.42473252, 6.13709878])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3481129248042641"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network homework\n",
    "# Based on:\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "sigmoid = scipy.special.expit\n",
    "def dsigmoid(s):\n",
    "    return sigmoid(s)*(1 - sigmoid(s))\n",
    "\n",
    "# constants\n",
    "alpha = 0.5\n",
    "x = np.array([0.3, 0.5])\n",
    "W1 = np.array([[0.5, 0.55], [0.6, 0.65]])\n",
    "(w1, w2), (w3, w4) = W1\n",
    "b1 = np.array([0.35, 0.35])\n",
    "W2 = np.array([[0.7, 0.75], [0.8, 0.85]])\n",
    "(w5, w6), (w7, w8) = W2\n",
    "b2 = np.array([0.6, 0.6])\n",
    "y = np.array([0.01, 0.99])\n",
    "# predictions\n",
    "yhat = sigmoid(W2 @ sigmoid(W1 @ x + b1) + b2)\n",
    "# error\n",
    "Etotal = sum(0.5*(y - yhat)**2)\n",
    "\n",
    "# partial results\n",
    "h = sigmoid(W1 @ x + b1)\n",
    "d1d2 = W1 @ x + b1\n",
    "d3d4 = W2 @ sigmoid(W1 @ x + b1) + b2\n",
    "c5c6 = y - yhat\n",
    "\n",
    "# \\partial Etotal / \\partial w5\n",
    "dLdw5 = -1 * h[0] * dsigmoid(d3d4)[0] * c5c6[0]\n",
    "\n",
    "# \\partial Etotal / \\partial w6\n",
    "dLdw6 = -1 * h[1] * dsigmoid(d3d4)[0] * c5c6[0]\n",
    "\n",
    "# \\partial Etotal / \\partial w7\n",
    "dLdw7 = -1 * h[0] * dsigmoid(d3d4)[1] * c5c6[1]\n",
    "\n",
    "# \\partial Etotal / \\partial w8\n",
    "dLdw8 = -1 * h[1] * dsigmoid(d3d4)[1] * c5c6[1]\n",
    "\n",
    "# \\partial Etotal / \\partial w1\n",
    "dLdw1 = -1 * x[0] * dsigmoid(d1d2)[0] * (w5 * dsigmoid(d3d4)[0] * c5c6[0] + w7 * dsigmoid(d3d4)[1] * c5c6[1])\n",
    "\n",
    "# \\partial Etotal / \\partial w2\n",
    "dLdw2 = -1 * x[1] * dsigmoid(d1d2)[0] * (w5 * dsigmoid(d3d4)[0] * c5c6[0] + w7 * dsigmoid(d3d4)[1] * c5c6[1])\n",
    "\n",
    "# \\partial Etotal / \\partial w3\n",
    "dLdw3 = -1 * x[0] * dsigmoid(d1d2)[1] * (w6 * dsigmoid(d3d4)[0] * c5c6[0] + w8 * dsigmoid(d3d4)[1] * c5c6[1])\n",
    "\n",
    "# \\partial Etotal / \\partial w4\n",
    "dLdw4 = -1 * x[1] * dsigmoid(d1d2)[1] * (w6 * dsigmoid(d3d4)[0] * c5c6[0] + w8 * dsigmoid(d3d4)[1] * c5c6[1])\n",
    "\n",
    "uw1 = w1 - alpha * dLdw1\n",
    "uw2 = w2 - alpha * dLdw2\n",
    "uw3 = w3 - alpha * dLdw3\n",
    "uw4 = w4 - alpha * dLdw4\n",
    "uw5 = w5 - alpha * dLdw5\n",
    "uw6 = w6 - alpha * dLdw6\n",
    "uw7 = w7 - alpha * dLdw7\n",
    "uw8 = w8 - alpha * dLdw8\n",
    "\n",
    "Etotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.775, 0.855]),\n",
       " array([0.684602, 0.701615]),\n",
       " array([1.605432, 1.744054]),\n",
       " array([-0.822776,  0.138799]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intermediate values\n",
    "d1d2, h, d3d4, c5c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.004284,  0.007141],\n",
       "        [ 0.004459,  0.007431]],\n",
       "\n",
       "       [[ 0.078441,  0.080391],\n",
       "        [-0.012035, -0.012334]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# derivates\n",
    "np.array([[[dLdw1, dLdw2], [dLdw3, dLdw4]], [[dLdw5, dLdw6], [dLdw7, dLdw8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.497858, 0.54643 ],\n",
       "        [0.597771, 0.646284]],\n",
       "\n",
       "       [[0.660779, 0.709805],\n",
       "        [0.806018, 0.856167]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated weights\n",
    "np.array([[[uw1, uw2], [uw3, uw4]], [[uw5, uw6], [uw7, uw8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.348113, grad_fn=<MulBackward0>)\n",
      "Torch gradients\n",
      "tensor([[0.004284, 0.007141],\n",
      "        [0.004459, 0.007431]], grad_fn=<CopyBackwards>)\n",
      "tensor([[ 0.078441,  0.080391],\n",
      "        [-0.012035, -0.012334]], grad_fn=<CopyBackwards>)\n",
      "Manually computed gradients\n",
      "[[[ 0.004284  0.007141]\n",
      "  [ 0.004459  0.007431]]\n",
      "\n",
      " [[ 0.078441  0.080391]\n",
      "  [-0.012035 -0.012334]]]\n",
      "Weights after update\n",
      "tensor([[0.497858, 0.546430],\n",
      "        [0.597771, 0.646284]], requires_grad=True)\n",
      "tensor([[0.660779, 0.709805],\n",
      "        [0.806018, 0.856167]], requires_grad=True)\n",
      "Manually weight update\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.497858, 0.54643 ],\n",
       "        [0.597771, 0.646284]],\n",
       "\n",
       "       [[0.660779, 0.709805],\n",
       "        [0.806018, 0.856167]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check answers for Neural Network homework using PyTorch\n",
    "W1 = torch.tensor([[0.5, 0.55], [0.6, 0.65]], requires_grad=True)\n",
    "W2 = torch.tensor([[0.7, 0.75], [0.8, 0.85]], requires_grad=True)\n",
    "b1 = torch.tensor([0.35, 0.35])\n",
    "b2 = torch.tensor([0.6, 0.6])\n",
    "x = torch.tensor([0.3, 0.5])\n",
    "y = torch.tensor([0.01, 0.99])\n",
    "\n",
    "optimizer = torch.optim.SGD([W1, W2], lr=0.5)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "yhat = torch.sigmoid(W2 @ torch.sigmoid(W1 @ x + b1) + b2)\n",
    "E_total = 0.5*torch.sum((y - yhat)**2)\n",
    "torch.set_printoptions(precision=6)\n",
    "print(E_total)\n",
    "E_total.backward(create_graph=True)\n",
    "print(\"Torch gradients\")\n",
    "print(W1.grad)\n",
    "print(W2.grad)\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "print(\"Manually computed gradients\")\n",
    "print(np.array([[[dLdw1, dLdw2], [dLdw3, dLdw4]], [[dLdw5, dLdw6], [dLdw7, dLdw8]]]))\n",
    "\n",
    "optimizer.step()\n",
    "print(\"Weights after update\")\n",
    "print(W1)\n",
    "print(W2)\n",
    "\n",
    "print(\"Manually weight update\")\n",
    "np.array([[[uw1, uw2], [uw3, uw4]], [[uw5, uw6], [uw7, uw8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
